{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.nn import functional as F\n",
    "import timm.models.mlp_mixer\n",
    "import numpy as np\n",
    "import exchange_tensor_array as exchange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from torchvision.datasets.utils import download_url\n",
    "import json\n",
    "\n",
    "import copy\n",
    "#モデル作成\n",
    "model = timm.create_model(\"gmlp_s16_224\", pretrained=True)\n",
    "model.eval()\n",
    "print(\"model\")\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),  # (256, 256) で切り抜く。\n",
    "        transforms.CenterCrop(224),  # 画像の中心に合わせて、(224, 224) で切り抜く\n",
    "        transforms.ToTensor(),  # テンソルにする。\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "        ),  # 標準化する。\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_beta = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),  # (256, 256) で切り抜く。\n",
    "        transforms.CenterCrop(224),  # 画像の中心に合わせて、(224, 224) で切り抜く\n",
    "    ]\n",
    ")\n",
    "\n",
    "img = Image.open(\"cat.jpg\")\n",
    "inputs = transform(img)\n",
    "inputs = inputs.unsqueeze(0)\n",
    "#plt.imshow(inputs[0].permute(1,2,0))\n",
    "copy_inputs = copy.deepcopy(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#クラス版テスト\n",
    "import cluster_ablation as ca\n",
    "exp = ca.cluster_ablation(model)\n",
    "shap_c = exp.calc_shapley_save_img(\"cat.jpg\", \"cat_reslut.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [i[0] for i in p]\n",
    "x = [i[1] for i in p]\n",
    "cover_img = np.zeros((224, 224, 4), dtype=np.uint8)\n",
    "for i in range(224):\n",
    "    for j in range(224):\n",
    "        cover_img[i, j, 3] = 0\n",
    "shap_max = max(shap_c)\n",
    "for i, j, c in zip(y, x, pred):\n",
    "    if shap[pred]\n",
    "    cover_img[i, j, 0] = 255\n",
    "    cover_img[i, j, 3] = 255\n",
    "cover_img = Image.fromarray(cover_img)\n",
    "base_img = transform_beta(img)\n",
    "base_img.paste(cover_img, (0, 0), cover_img)\n",
    "plt.imshow(base_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(inputs_c[39][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output0 = model(inputs)\n",
    "mid0 = model.blocks[0].block_output\n",
    "mid0 = exchange.exchange_tensor_to_array(mid0)\n",
    "plt.imshow(mid0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "y, x = np.where((abs(mid0) > 2.7235))\n",
    "l = len(y)\n",
    "p = [ [y[i], x[i]] for i in range(l)]\n",
    "print(l)\n",
    "tmp = np.zeros((224, 224))\n",
    "for u, v in p:\n",
    "    tmp[u, v] = 10\n",
    "exchange.show_heatmap_with_colorbar(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 50, 2):\n",
    "    y, x = np.where((abs(mid0) > i * 0.1))\n",
    "    print(i * 0.1, len(y))\n",
    "    tmp = np.zeros((224, 224))\n",
    "    for u, v in zip(y, x):\n",
    "        tmp[u, v] = 10\n",
    "    exchange.show_heatmap_with_colorbar(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = np.where((abs(mid0) > 2.7235))\n",
    "l = len(y)\n",
    "p = [ [y[i], x[i]] for i in range(l)]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(1, 21):\n",
    "    db = DBSCAN(eps=9, min_samples = i)\n",
    "    pred = db.fit_predict(p)\n",
    "    n_c = set(pred)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.scatter(x, y, s=100, c=pred, cmap=\"Blues\")\n",
    "    plt.colorbar()\n",
    "    plt.xlim(0, 223)\n",
    "    plt.ylim(223, 0)\n",
    "    res.append((len(n_c), list(pred).count(-1)))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "db = DBSCAN(eps=9, min_samples=5)\n",
    "pred = db.fit_predict(p)\n",
    "n_c = set(pred)\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(x, y, s=100, c=pred, cmap=\"Blues\")\n",
    "plt.colorbar()\n",
    "plt.xlim(0, 223)\n",
    "plt.ylim(223, 0)\n",
    "len(set(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 21):\n",
    "    db = DBSCAN(eps=8, min_samples=i)\n",
    "    pred = db.fit_predict(p)\n",
    "    n_c = set(pred)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.scatter(x, y, s = 100, c = pred, cmap=\"Blues\")\n",
    "    plt.colorbar()\n",
    "    plt.xlim(0, 223)\n",
    "    plt.ylim(223, 0)\n",
    "    print(len(set(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shaply値を愚直に\n",
    "from scipy.spatial import ConvexHull, Delaunay\n",
    "from collections import defaultdict\n",
    "class shaply_from_first_mid_output():\n",
    "    \n",
    "    def __init__(self, model : timm.models.mlp_mixer.MlpMixer) -> None:\n",
    "        self.model = model\n",
    "        self.class_names = None\n",
    "        self.get_classes()\n",
    "        self.inputs = []\n",
    "        self.values = []\n",
    "        self.block_output = None\n",
    "        self.block_output_exchanged = None\n",
    "        \n",
    "        \n",
    "    def get_classes(self):\n",
    "        if not Path(\"data/imagenet_class_index.json\").exists():\n",
    "            # ファイルが存在しない場合はダウンロードする。\n",
    "            download_url(\"https://git.io/JebAs\", \"data\", \"imagenet_class_index.json\")\n",
    "\n",
    "        # クラス一覧を読み込む。\n",
    "        with open(\"data/imagenet_class_index.json\") as f:\n",
    "            data = json.load(f)\n",
    "            self.class_names = [x[\"ja\"] for x in data]\n",
    "\n",
    "    def base_model_output(self, _input : torch.Tensor) -> tuple:\n",
    "        \"\"\"画像をモデルに入力した際の一番スコアが高いラベルとそのスコアを返す\"\"\"\n",
    "        base_output = self.model(_input)\n",
    "        batch_probs = F.softmax(base_output, dim=1)\n",
    "        batch_probs, batch_indices = batch_probs.sort(dim=1, descending=True)\n",
    "\n",
    "        return (self.class_names[batch_indices[0][0]], batch_probs[0][0].item())\n",
    "\n",
    "    def in_hull_(self, point : list, hull : list):\n",
    "        \"\"\"点群hullからなる凸包内に点pointが入っているかを判定\"\"\"\n",
    "        if not isinstance(hull, Delaunay):\n",
    "            hull = Delaunay(hull)\n",
    "        return hull.find_simplex(point) >= 0\n",
    "\n",
    "\"\"\"\n",
    "    def cal_paras_filitering(self):\n",
    "        #にぶたんとかでフィルタリングのパラメータを求める\n",
    "        return フィルタリングのパラメータ\n",
    "    \n",
    "    def cal_paras_DESCAN(self):\n",
    "        #にぶたんとかでDBSCANのパラメータを求める\n",
    "        return DBSCANのパラメータ\n",
    "    \n",
    "    def clustering(self):\n",
    "        #DBSCAMを行って、クラスタのラベルを返す\n",
    "        return pred\n",
    "\"\"\"\n",
    "\n",
    "    def calc_shaply(img : torch.Tensor):\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #クラスタごとに点群を求める。各点群の座標の最大値最小値も記録しておく\n",
    "        clusters = defaultdict(lambda : [])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shaply値を愚直に\n",
    "from scipy.spatial import ConvexHull, Delaunay\n",
    "from collections import defaultdict\n",
    "from math import factorial\n",
    "def in_hull_(point : list, hull : list):\n",
    "        \"\"\"点群hullからなる凸包内に点pointが入っているかを判定\"\"\"\n",
    "        if not isinstance(hull, Delaunay):\n",
    "            hull = Delaunay(hull)\n",
    "        return hull.find_simplex(point) >= 0\n",
    "    \n",
    "    \n",
    "def get_classes():\n",
    "    if not Path(\"data/imagenet_class_index.json\").exists():\n",
    "        # ファイルが存在しない場合はダウンロードする。\n",
    "        download_url(\"https://git.io/JebAs\", \"data\", \"imagenet_class_index.json\")\n",
    "\n",
    "    # クラス一覧を読み込む。\n",
    "    with open(\"data/imagenet_class_index.json\") as f:\n",
    "        data = json.load(f)\n",
    "        class_names = [x[\"ja\"] for x in data]\n",
    "    return class_names\n",
    "\n",
    "class_names = get_classes()\n",
    "\n",
    "def base_model_output(_input : torch.Tensor) -> tuple:\n",
    "    \"\"\"画像をモデルに入力した際の一番スコアが高いラベルとそのスコアを返す\"\"\"\n",
    "    base_output = model(_input)\n",
    "    batch_probs = F.softmax(base_output, dim=1)\n",
    "    batch_probs, batch_indices = batch_probs.sort(dim=1, descending=True)\n",
    "    \n",
    "    return (class_names[batch_indices[0][0]], batch_probs[0][0].item())\n",
    "\n",
    "def calc_shaply(img : torch.Tensor, y : np.ndarray, x : np.ndarray, pred : np.ndarray):\n",
    "    \n",
    "    inputs = []\n",
    "    values = []\n",
    "    \n",
    "    \n",
    "    #クラスタ数\n",
    "    n_c = len(set(pred)) - 1\n",
    "    #shaply値格納\n",
    "    shap = [0] * n_c\n",
    "    #各マスクされた画像に対するスコア格納\n",
    "    probs = [0] * pow(2, n_c)\n",
    "    #マスクする際のバックアップ\n",
    "    input_backup = defaultdict(lambda : [])\n",
    "    \n",
    "    \n",
    "    #元々のスコアとクラス名とそのインデックスを取得。便宜上ここにおいておく\n",
    "    base_class_name, base_prob = base_model_output(img)\n",
    "    base_class_index = class_names.index(base_class_name)\n",
    "    \n",
    "    num = []\n",
    "    \n",
    "    \n",
    "    #クラスタごとに点群を求める。各点群の座標の最大値最小値も記録しておく\n",
    "    clusters = defaultdict(lambda : [])\n",
    "    left = defaultdict(lambda : 1000)\n",
    "    right = defaultdict(lambda : -1000)\n",
    "    up = defaultdict(lambda : 1000)\n",
    "    down = defaultdict(lambda : -1000)\n",
    "    \n",
    "    for v, u, c in zip(y, x, pred):\n",
    "        if c == -1:\n",
    "            continue\n",
    "        clusters[c].append((v, u))\n",
    "        left[c] = min(left[c], u)\n",
    "        right[c] = max(right[c], u)\n",
    "        up[c] = min(up[c], v)\n",
    "        down[c] = max(down[c], v)\n",
    "        \n",
    "\n",
    "    #全組み合わせを総当たり\n",
    "    for i in range(2 ** n_c):\n",
    "        flag = [True] * n_c #マスクされていたらFalse\n",
    "        input_backup = defaultdict(lambda : [])\n",
    "        for c in range(n_c):\n",
    "            if i >> c & 1:\n",
    "                flag[c] = False\n",
    "                #マスクする\n",
    "                for v in range(up[c], down[c] + 1):\n",
    "                    for u in range(left[c], right[c] + 1):\n",
    "                        if in_hull_([v, u], clusters[c]):\n",
    "                            r, b, g = img[0, 0, v, u].item(), img[0, 1, v, u].item(), img[0, 2, v, u].item()\n",
    "                            input_backup[(v, u)] = [r, b, g]\n",
    "                            img[0, 0, v, u] = 0\n",
    "                            img[0, 1, v, u] = 0\n",
    "                            img[0, 2, v, u] = 0\n",
    "\n",
    "        \n",
    "        #モデルに流してスコアを得る\n",
    "        tmp_output = model(img)\n",
    "        tmp_batch_probs = F.softmax(tmp_output, dim=1)\n",
    "        tmp_prob = tmp_batch_probs[0][base_class_index].item()\n",
    "        \n",
    "        probs[i] = tmp_prob\n",
    "        \n",
    "        \"\"\"\n",
    "        for c in range(n_c):\n",
    "            if flag[c]:\n",
    "                shap[c] += tmp_prob\n",
    "        \"\"\"\n",
    "        \n",
    "        inputs.append(copy.deepcopy(img))\n",
    "        values.append(tmp_prob)\n",
    "        \n",
    "        #入力画像を元に戻す\n",
    "        for key, val in input_backup.items():\n",
    "            v, u = key\n",
    "            r, b, g = val\n",
    "            img[0, 0, v, u] = r\n",
    "            img[0, 1, v, u] = b\n",
    "            img[0, 2, v, u] = g\n",
    "    \n",
    "    for i in range(2 ** n_c):\n",
    "        count = 0\n",
    "        p = []\n",
    "        for j in range(n_c):\n",
    "            if i >> j & 1:\n",
    "                count += 1\n",
    "            else:\n",
    "                p.append(j)\n",
    "        for j in p:\n",
    "            tmp = factorial(count) * factorial(n_c - count - 1) * (-probs[i + pow(2, j)] + probs[i]) / factorial(n_c)\n",
    "            shap[j] += tmp\n",
    "            print(tmp,probs[i + pow(2, j)],probs[i])\n",
    "            num.append(i + pow(2, j))\n",
    "            num.append(i)\n",
    "    \n",
    "    \n",
    "    return shap, inputs, values, num\n",
    "        \n",
    "    \n",
    "                            \n",
    "def meguru_bisect_for_filitering(mid_output : np.ndarray, border = 300) -> float:\n",
    "    \"\"\"中間層の出力をフィルタリングする閾値をピックアップする特徴量の数を基に二分探索で求める\"\"\"\n",
    "    ok = 0\n",
    "    ng = max(abs(mid_output.max()), abs(mid_output.min())) + 1\n",
    "    while abs(ok - ng) > 0.01:\n",
    "        mid = (ok + ng) / 2\n",
    "        print(mid)\n",
    "        if len(np.where(abs(mid_output) > mid)[0]) >= border:\n",
    "            ok = mid\n",
    "        else:\n",
    "            ng = mid\n",
    "    return ok\n",
    "                \n",
    "                \n",
    "                \n",
    "def calc_shaply_beta(img : torch.Tensor, y : np.ndarray, x : np.ndarray, pred : np.ndarray):\n",
    "    \n",
    "    inputs = []\n",
    "    values = []\n",
    "    \n",
    "    \n",
    "    #クラスタ数\n",
    "    n_c = len(set(pred))\n",
    "    #shaply値格納\n",
    "    shap = [0] * n_c\n",
    "    #各マスクされた画像に対するスコア格納\n",
    "    probs = [0] * pow(2, n_c)\n",
    "    #マスクする際のバックアップ\n",
    "    input_backup = defaultdict(lambda : [])\n",
    "    \n",
    "    \n",
    "    #元々のスコアとクラス名とそのインデックスを取得。便宜上ここにおいておく\n",
    "    base_class_name, base_prob = base_model_output(img)\n",
    "    base_class_index = class_names.index(base_class_name)\n",
    "    \n",
    "    num = []\n",
    "    \n",
    "    \n",
    "    #クラスタごとに点群を求める。各点群の座標の最大値最小値も記録しておく\n",
    "    clusters = defaultdict(lambda : [])\n",
    "    left = defaultdict(lambda : 1000)\n",
    "    right = defaultdict(lambda : -1000)\n",
    "    up = defaultdict(lambda : 1000)\n",
    "    down = defaultdict(lambda : -1000)\n",
    "    \n",
    "    for v, u, c in zip(y, x, pred):\n",
    "        if c == -1:\n",
    "            continue\n",
    "        clusters[c].append((v, u))\n",
    "        left[c] = min(left[c], u)\n",
    "        right[c] = max(right[c], u)\n",
    "        up[c] = min(up[c], v)\n",
    "        down[c] = max(down[c], v)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #各画素ごとにどのクラスタの凸包に属するかを判定\n",
    "    masks = defaultdict(lambda : [])\n",
    "    mask_flag = [ [True] * 224 for _ in range(224)]\n",
    "    \n",
    "    for c in range(n_c - 1):\n",
    "        for i in range(up[c], down[c] + 1):\n",
    "            for j in range(left[c], right[c] + 1):\n",
    "                if in_hull_([i, j], clusters[c]):\n",
    "                    masks[c].append((i, j))\n",
    "                    mask_flag[i][j] = False\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            if mask_flag[i][j]:\n",
    "                #img[0, 0, i, j] = 255\n",
    "                #img[0, 1, i, j] = 255\n",
    "                #img[0, 2, i, j] = 255\n",
    "                masks[n_c - 1].append((i, j))\n",
    "                \n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            flag = True\n",
    "            for c in range(n_c):\n",
    "                if in_hull_((i, j), clusters[c]):\n",
    "                    masks[c].append((i, j))\n",
    "                    flag = False\n",
    "                    break\n",
    "            if flag:\n",
    "                masks[n_c - 1].append((i, j))\n",
    "    \"\"\"\n",
    "        \n",
    "\n",
    "    #全組み合わせを総当たり\n",
    "    for i in range(2 ** n_c):\n",
    "        input_backup = defaultdict(lambda : [])\n",
    "        for c in range(n_c):\n",
    "            if i >> c & 1:\n",
    "                #マスクする\n",
    "                for y, x in masks[c]:\n",
    "                    r, b, g = img[0, 0, y, x].item(), img[0, 1, y, x].item(), img[0, 2, y, x].item()\n",
    "                    input_backup[(y, x)] = [r, b, g]\n",
    "                    img[0, 0, y, x] = 0\n",
    "                    img[0, 1, y, x] = 0\n",
    "                    img[0, 2, y, x] = 0\n",
    "\n",
    "        \n",
    "        #モデルに流してスコアを得る\n",
    "        tmp_output = model(img)\n",
    "        tmp_batch_probs = F.softmax(tmp_output, dim=1)\n",
    "        tmp_prob = tmp_batch_probs[0][base_class_index].item()\n",
    "        \n",
    "        probs[i] = tmp_prob\n",
    "        \n",
    "        inputs.append(copy.deepcopy(img))\n",
    "        values.append(tmp_prob)\n",
    "        \n",
    "        #入力画像を元に戻す\n",
    "        for key, val in input_backup.items():\n",
    "            v, u = key\n",
    "            r, b, g = val\n",
    "            img[0, 0, v, u] = r\n",
    "            img[0, 1, v, u] = b\n",
    "            img[0, 2, v, u] = g\n",
    "    \n",
    "    for i in range(2 ** n_c):\n",
    "        count = 0\n",
    "        p = []\n",
    "        for j in range(n_c):\n",
    "            if i >> j & 1:\n",
    "                count += 1\n",
    "            else:\n",
    "                p.append(j)\n",
    "        for j in p:\n",
    "            tmp = factorial(count) * factorial(n_c - count - 1) * (-probs[i + pow(2, j)] + probs[i]) / factorial(n_c)\n",
    "            shap[j] += tmp\n",
    "            #print(tmp,probs[i + pow(2, j)],probs[i])\n",
    "            num.append(i + pow(2, j))\n",
    "            num.append(i)\n",
    "    \n",
    "    \n",
    "    return shap, inputs, values, num, masks, clusters, left, right, up, down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#クラス版テスト\n",
    "import cluster_ablation as ca\n",
    "exp = ca.cluster_ablation(model)\n",
    "shap_c, inputs_c, values_c, masks_c, p_c, pred_c, mask_flag_c = exp.calc_shapley(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#クラス版テスト\n",
    "import cluster_ablation as ca\n",
    "exp = ca.cluster_ablation(model)\n",
    "shap_c, inputs_c, values_c, masks_c, p_c, pred_c, mask_flag_c, clus_c, left_c, rihgt_c, up_c, down_c = exp.calc_shapley(inputs)\n",
    "shap, _inputs, values, num, masks, clusters, left, right, up, down = calc_shaply_beta(inputs, y, x, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap == shap_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap, _inputs, values, num, masks, clusters, left, right, up, down = calc_shaply_beta(inputs, y, x, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[y[i], x[i], pred[i]] for i in range(len(y))]\n",
    "b = [[p_c[i][0], p_c[i][1], pred_c[i]] for i in range(len(p))]\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = defaultdict(lambda : [])\n",
    "mask_f = [ [-1] * 224 for _ in range(224)]\n",
    "clus = defaultdict(lambda : [])\n",
    "for i, j, c in zip(y, x, pred):\n",
    "    clus[c].append((i, j))\n",
    "l = len(pred)\n",
    "for c in range(l - 1):\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            if in_hull_([i, j], clus[c]):\n",
    "                mask[c].append((i, j))\n",
    "                mask_f[i][j] = c\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_flag_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [ len(i) for i in masks.values()]\n",
    "b = [len(i) for i in masks_c.values()]\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_c_sorted = sorted(probs_c)\n",
    "values_sorted = sorted(values)\n",
    "print(len(probs_c_sorted), len(values_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, j in zip(probs_c_sorted, values_sorted):\n",
    "    if i != j:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in masks.keys():\n",
    "    print(\"len mask[{}] : {}\".format(k, len(masks[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_class_name, base_prob = base_model_output(inputs)\n",
    "base_class_index = class_names.index(base_class_name)\n",
    "tmp_output = model(_inputs[2**5])\n",
    "tmp_batch_probs = F.softmax(tmp_output, dim=1)\n",
    "tmp_prob = tmp_batch_probs[0][base_class_index].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(_inputs[0][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_img = np.zeros((224, 224, 4), dtype=np.uint8)\n",
    "for i in range(224):\n",
    "    for j in range(224):\n",
    "        cover_img[i, j, 3] = 0\n",
    "shap_max = max(shap_c[0][:-1])\n",
    "for i, c in zip(shap_c[1], shap_c[2]):\n",
    "    if c == -1 or shap_c[0][c] < shap_max / 2:\n",
    "        continue\n",
    "    y, x = i\n",
    "    cover_img[y, x, 0] = 255 * shap_c[0][c] / shap_max\n",
    "    cover_img[y, x, 3] = 255\n",
    "cover_img = Image.fromarray(cover_img)\n",
    "base_img = transform_beta(img)\n",
    "base_img.paste(cover_img, (0, 0), cover_img)\n",
    "plt.imshow(base_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(base_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cover_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img = transform_beta(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(base_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img.paste(cover_img, (0, 0), cover_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(base_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.scatter(x, y, s=100, c=pred, cmap=\"Blues\")\n",
    "plt.colorbar()\n",
    "plt.xlim(0, 223)\n",
    "plt.ylim(223, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#クラスタごとに点群を求める。各点群の座標の最大値最小値も記録しておく\n",
    "clusters = defaultdict(lambda : [])\n",
    "left = defaultdict(lambda : 1000)\n",
    "right = defaultdict(lambda : -1000)\n",
    "up = defaultdict(lambda : 1000)\n",
    "down = defaultdict(lambda : -1000)\n",
    "\n",
    "for v, u, c in zip(y, x, pred):\n",
    "    if c == -1:\n",
    "        continue\n",
    "    clusters[c].append((v, u))\n",
    "    left[c] = min(left[c], u)\n",
    "    right[c] = max(right[c], u)\n",
    "    up[c] = min(up[c], v)\n",
    "    down[c] = max(down[c], v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(5):\n",
    "    for i, j in clusters[c]:\n",
    "        if not in_hull_([i, j], clusters[c]):\n",
    "            print(\"not in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(5):\n",
    "    print(left[c], right[c], up[c],down[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = model.blocks[0].block_output\n",
    "mid = exchange.exchange_tensor_to_array(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange.show_heatmap_with_colorbar(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(mid<-0.5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = torch.ones(1,3,224,224)\n",
    "tmp2 *= 255\n",
    "output2 = model(tmp2)\n",
    "mid2 = model.blocks[0].block_output\n",
    "mid2 = exchange.exchange_tensor_to_array(mid2)\n",
    "exchange.show_heatmap_with_colorbar(mid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(abs(mid2) < 10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid2b = np.where(abs(mid2) < 25, 255, 0)\n",
    "plt.imshow(mid2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid3 = mid + mid2 / 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange.show_heatmap_with_colorbar(mid3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
