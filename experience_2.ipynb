{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#セグメンテーションファイルのパス取得\n",
    "import glob\n",
    "\n",
    "xml_files = glob.glob(\"annotations/annotations/trimaps/*\")\n",
    "file_names = []\n",
    "for file in xml_files:\n",
    "    if file[0] != \".\":\n",
    "        file_names.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#アスペクト比でふるいわけ\n",
    "from PIL import Image\n",
    "path = \"pet_dataset/\"\n",
    "data = []\n",
    "ng = []\n",
    "for file_name in file_names:\n",
    "    try:\n",
    "        img = Image.open(path + file_name[32:-3] + \"jpg\") \n",
    "        x, y = img.size\n",
    "        if x >= y:\n",
    "            rate = x / y\n",
    "        else:\n",
    "            rate = y / x\n",
    "        data.append([rate, file_name[32:-3] + \"jpg\"])\n",
    "    except:\n",
    "        ng.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for rate, file in data:\n",
    "    if rate == 1:\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n"
     ]
    }
   ],
   "source": [
    "import cluster_ablation as ca\n",
    "import timm\n",
    "\n",
    "import sys\n",
    "\n",
    "import time\n",
    "import slackweb\n",
    "slack = slackweb.Slack(\"https://hooks.slack.com/services/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\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#モデル作成\n",
    "model = timm.create_model(\"gmlp_s16_224\", pretrained=True)\n",
    "model.eval()\n",
    "print(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import orig_argv\n",
    "from pathlib import Path\n",
    "from torchvision.datasets.utils import download_url\n",
    "import json\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def get_classes():\n",
    "    if not Path(\"data/imagenet_class_index.json\").exists():\n",
    "        # ファイルが存在しない場合はダウンロードする。\n",
    "        download_url(\"https://git.io/JebAs\", \"data\", \"imagenet_class_index.json\")\n",
    "\n",
    "    # クラス一覧を読み込む。\n",
    "    with open(\"data/imagenet_class_index.json\") as f:\n",
    "        data = json.load(f)\n",
    "        class_names = [x[\"ja\"] for x in data]\n",
    "\n",
    "    return class_names\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),  # (256, 256) で切り抜く。\n",
    "        transforms.CenterCrop(224),  # 画像の中心に合わせて、(224, 224) で切り抜く\n",
    "        transforms.ToTensor(),  # テンソルにする。\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "        ),  # 標準化する。\n",
    "    ]\n",
    ")\n",
    "# クラス名一覧を取得する。\n",
    "class_names = get_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#予測スコアでふるい分け\n",
    "res = []\n",
    "for rate, file_name in data[:116]:\n",
    "    path = \"pet_dataset/\" + file_name\n",
    "    img = Image.open(path)\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    output = model(img)\n",
    "    batch_probs = F.softmax(output, dim = 1)\n",
    "    batch_probs, batch_indices = batch_probs.sort(dim = 1, descending=True)\n",
    "    class_name = class_names[batch_indices[0][0]]\n",
    "    prob = batch_probs[0][0].item()\n",
    "    res.append([prob, class_name, rate, file_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_files = res[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#セグメンテーション画像の読み込み\n",
    "seg_path = \"annotations/annotations/trimaps/\" + \"Bengal_113.png\"\n",
    "import matplotlib.pyplot as plt\n",
    "seg_img = Image.open(seg_path)\n",
    "transform_beta = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),  # (256, 256) で切り抜く。\n",
    "        transforms.CenterCrop(224),  # 画像の中心に合わせて、(224, 224) で切り抜く\n",
    "    ]\n",
    ")\n",
    "seg_img = transform_beta(seg_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "動物：1, 外側：2, 境界線：3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_val_from_mappedarray(mapped_array : list, seg_path : str) -> list:\n",
    "    #セグメンテーション画像の読み込み\n",
    "    seg_img = Image.open(seg_path)\n",
    "    seg_img = transform_beta(seg_img)\n",
    "    \n",
    "    res = [0, 0, 0, 0, 0 , 0] \n",
    "    # 0:領域内でマッピングされてる 1:領域内でマッピングされていない \n",
    "    # 2:境界線でマッピングされてる 3:境界線でマッピングされていない \n",
    "    # 4: 領域外でマッピングされている 5:領域外でマッピングされていない\n",
    "    \n",
    "    for y in range(224):\n",
    "        for x in range(224):\n",
    "            tmp = seg_img.getpixel((x, y))\n",
    "            if tmp == 1: #領域内\n",
    "                if mapped_array[y][x] == True: #マッピングされている\n",
    "                    res[0] += 1\n",
    "                else:#マッピングされていない\n",
    "                    res[1] += 1\n",
    "            elif tmp == 3:#境界線\n",
    "                if mapped_array[y][x] == True: #マッピングされている\n",
    "                    res[2] += 1\n",
    "                else:#マッピングされていない\n",
    "                    res[3] += 1\n",
    "            elif tmp == 2:#領域外\n",
    "                if mapped_array[y][x] == True: #マッピングされている\n",
    "                    res[4] += 1\n",
    "                else:#マッピングされていない\n",
    "                    res[5] += 1\n",
    "    return res\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "transform_beta = transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(256),  # (256, 256) で切り抜く。\n",
    "                transforms.CenterCrop(224),  # 画像の中心に合わせて、(224, 224) で切り抜く\n",
    "            ]\n",
    "        )\n",
    "\n",
    "def cal_val_from_lime_img(lime_img : np.array, seg_path : str) -> list:\n",
    "    #セグメンテーション画像の読み込み\n",
    "    seg_img = Image.open(seg_path)\n",
    "    seg_img = transform_beta(seg_img)\n",
    "    \n",
    "    res = [0, 0, 0, 0, 0 , 0] \n",
    "    # 0:領域内でマッピングされてる 1:領域内でマッピングされていない \n",
    "    # 2:境界線でマッピングされてる 3:境界線でマッピングされていない \n",
    "    # 4: 領域外でマッピングされている 5:領域外でマッピングされていない\n",
    "    \n",
    "    a = np.array([0, 0, 0]) #比較対象用配列\n",
    "    for y in range(224):\n",
    "        for x in range(224):\n",
    "            tmp = seg_img.getpixel((x, y))\n",
    "            if tmp == 1: #領域内\n",
    "                if np.array_equal(lime_img[y, x], a) == False: #マッピングされている\n",
    "                    res[0] += 1\n",
    "                else:#マッピングされていない\n",
    "                    res[1] += 1\n",
    "            elif tmp == 3:#境界線\n",
    "                if np.array_equal(lime_img[y, x], a) == False: #マッピングされている\n",
    "                    res[2] += 1\n",
    "                else:#マッピングされていない\n",
    "                    res[3] += 1\n",
    "            elif tmp == 2:#領域外\n",
    "                if np.array_equal(lime_img[y, x], a) == False: #マッピングされている\n",
    "                    res[4] += 1\n",
    "                else:#マッピングされていない\n",
    "                    res[5] += 1\n",
    "    return res \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ca.cluster_ablation(model)\n",
    "res = []\n",
    "exp2_res = {}\n",
    "count = 0\n",
    "tds = {}\n",
    "\n",
    "ok_jpg_name = [i[-1] for i in ok_files]\n",
    "\n",
    "try:\n",
    "    for rate in [0.5, 0.8, 1]:\n",
    "            for k in [5, 7, 9, 10, 11, 13, 15]:\n",
    "                t1 = time.time()\n",
    "                tmp_res = []\n",
    "                for jpg_name in ok_jpg_name:\n",
    "                    jpg_path = \"pet_dataset/\" + jpg_name\n",
    "                    output_path = \"reslut_pet_dataset/exp2/dbscan_and_kmeans/300/take1/\" + jpg_path[12:]\n",
    "                    seg_path = \"annotations/annotations/trimaps/\" + jpg_name[:-3] + \"png\"\n",
    "                    values, p, pred, masks, base_img, masked_img, mapped_array = exp.calc_prob_save_img_by_dbscan_and_kmeans(input_path=jpg_path, output_path=output_path, border=300, eps=15, min_samples=5, k=k, value_border=(1 / k) * rate, save=True)\n",
    "                    exp2_values = cal_val_from_mappedarray(mapped_array=mapped_array, seg_path=seg_path)\n",
    "                    exp2_values.append(jpg_name)\n",
    "                    tmp_res.append(exp2_values)\n",
    "                t2 = time.time()\n",
    "                td = t2 - t1\n",
    "                key = (rate, k)\n",
    "                exp2_res[key] = tmp_res\n",
    "                tds[key] = td\n",
    "                print((key))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    slack.notify(text=\"えらー\")\n",
    "slack.notify(text=\"しゅーりょー\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_res[(1, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#txtに書き込み\n",
    "for key in exp2_res.keys():\n",
    "    rate, k = key\n",
    "    path = \"reslut_pet_dataset/exp2/dbscan_and_kmeans/300/result1/result_min_samples_{}_rate_{}_k_{}.txt\".format(5, int(rate * 100), k)\n",
    "    path = \"reslut_pet_dataset/exp2/dbscan_and_kmeans/300/resuit1/result_min_samples_{}_rate_{}_k_{}.txt\".format(5, int(rate * 100), k)\n",
    "    with open(path, mode = \"w\") as f:\n",
    "        f.write(\"### border=300, eps=15, min_samples={}, k={}, value_border=(1 / {}) * {}\\n\".format(5, k, k, rate))\n",
    "        f.write(\"### 所要時間 {} sec\\n\".format(tds[key]))\n",
    "        for s in exp2_res[key]:\n",
    "            tmp = \" \".join(map(str, s)) + \"\\n\"\n",
    "            f.write(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#エクセルに書き込み\n",
    "import openpyxl\n",
    "def write_list_2d(sheet, l_2d, start_row, start_col):\n",
    "    for y, row in enumerate(l_2d):\n",
    "        for x, cell in enumerate(row):\n",
    "            sheet.cell(row=start_row + y,\n",
    "                       column=start_col + x,\n",
    "                       value=l_2d[y][x])\n",
    "path = \"reslut_pet_dataset/exp2/dbscan_and_kmeans/300/集計.xlsx\"\n",
    "wb = openpyxl.load_workbook(path)\n",
    "sheet = wb[\"Sheet1\"]\n",
    "l_2d = []\n",
    "for key in exp2_res.keys():\n",
    "    rate, k = key\n",
    "    tmp = [rate, k, 0, 0, 0, 0, 0, 0]\n",
    "    for a in exp2_res[key]:\n",
    "        for i in range(6):\n",
    "            tmp[i + 2] += a[i]\n",
    "    tmp.append(tds[key])\n",
    "    l_2d.append(tmp)\n",
    "write_list_2d(sheet=sheet, l_2d=l_2d, start_col=2, start_row=2)\n",
    "print(list(sheet.values)) \n",
    "wb.save(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import timm\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.nn import functional as F\n",
    "import timm.models.mlp_mixer\n",
    "import numpy as np\n",
    "import exchange_tensor_array as exchange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from torchvision.datasets.utils import download_url\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import glob\n",
    "\n",
    "import time\n",
    "\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import slackweb\n",
    "slack = slackweb.Slack(\"https://hooks.slack.com/services/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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデル作成\n",
    "model = timm.create_model(\"gmlp_s16_224\", pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "#lime用の関数\n",
    "def get_pil_transform(): \n",
    "    transf = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224)\n",
    "    ])    \n",
    "\n",
    "    return transf\n",
    "\n",
    "def get_preprocess_transform():\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])     \n",
    "    transf = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])    \n",
    "\n",
    "    return transf    \n",
    "\n",
    "pill_transf = get_pil_transform()\n",
    "preprocess_transform = get_preprocess_transform()\n",
    "\n",
    "def batch_predict(images):\n",
    "    model.eval()\n",
    "    batch = torch.stack(tuple(preprocess_transform(i) for i in images), dim=0)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    logits = model(batch)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    return probs.detach().cpu().numpy()\n",
    "explainer = lime_image.LimeImageExplainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_rest == True ver\n",
    "\n",
    "ok_jpg_name = [i[-1] for i in ok_files]\n",
    "\n",
    "for jpg_name in ok_jpg_name:\n",
    "    try:\n",
    "        input_path = \"pet_dataset/\" + jpg_name\n",
    "        img = Image.open(input_path)\n",
    "        explanation = explainer.explain_instance(np.array(pill_transf(img)), \n",
    "                                                batch_predict, # classification function\n",
    "                                                top_labels=1, \n",
    "                                                hide_color=0, \n",
    "                                                num_samples=1000) # number of images that will be sent to classification function\n",
    "        temp1, mask1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=11, hide_rest=True)\n",
    "        img_boundry1 = mark_boundaries(temp1/255.0, mask1)\n",
    "        plt.imsave(\"reslut_pet_dataset/exp2/lime/hide_rest/\" + jpg_name, img_boundry1)\n",
    "    except Exception as e:\n",
    "        slack.notify(text=\"えらー\")\n",
    "slack.notify(text=\"しゅーりょー\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_img = Image.open(\"reslut_pet_dataset/exp2/LIME/hide_rest/Bengal_113.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lime_img)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2fd01f95294d4690128d29d89cc7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basset_hound_23.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e19064726145bdaee34a30ea3bfc9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxer_64.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061b1c34bed34499be3f082ba3a65e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newfoundland_198.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6990fca883a84d5a9a558f40f60c0438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphynx_72.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdeb9ab8780d4feca7a40e11ea2c642c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keeshond_6.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699b45bd078842ec8b16e055bee1eed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chihuahua_38.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db89f0c35f3046b4a131d0b10fda1ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siamese_210.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7764dac7e146c99cdca44b5df84636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Egyptian_Mau_118.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb0a0920dfe4a0cb820050453960a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persian_105.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d2931b52364c7199ecd0b36abe0390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keeshond_182.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b53ee040b004c00b56de73cf98f8467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphynx_46.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79e6784f0db46f193b258853d66e86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birman_68.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb28b396738947e3ac3c49da0f1fb466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chihuahua_9.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebeb15f3af54eb6af59436f141d0a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragdoll_52.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554560a282f34e31aff8a0b81cb31627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basset_hound_22.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b3630e41864a88baa5536646819b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scottish_terrier_183.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bca5a1e3aa4175904a9128ee7bc8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chihuahua_61.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76324cd0ef254318a0ec4c545da157e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Egyptian_Mau_52.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e74e15b75e3463bb87b236d8f4eca47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphynx_230.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c706e1bc7c246a0a7210a3d38480fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragdoll_53.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf905224f1f44c119c480b00c00cec64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newfoundland_186.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdecb0f1ab74c6e99262a9c3485c744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bombay_21.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467a9b4ac9c54816834bb910577b1e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shiba_inu_93.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235d6f1021b8433a97b88c9ac2c17671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Egyptian_Mau_80.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc77714b6d234471ad333fd20bfc9bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bengal_113.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#limeで実験\n",
    "# hide_rest == True ver\n",
    "\n",
    "ok_jpg_name = [i[-1] for i in ok_files]\n",
    "\n",
    "lime_exp2_res = []\n",
    "for jpg_name in ok_jpg_name:\n",
    "    try:\n",
    "        t1 = time.time()\n",
    "        input_path = \"pet_dataset/\" + jpg_name\n",
    "        img = Image.open(input_path)\n",
    "        explanation = explainer.explain_instance(np.array(pill_transf(img)), \n",
    "                                                batch_predict, # classification function\n",
    "                                                top_labels=1, \n",
    "                                                hide_color=0, \n",
    "                                                num_samples=1000) # number of images that will be sent to classification function\n",
    "        temp1, mask1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=11, hide_rest=True)\n",
    "        img_boundry1 = mark_boundaries(temp1/255.0, mask1)\n",
    "        t2 = time.time()\n",
    "        td = t2 - t1\n",
    "        plt.imsave(\"reslut_pet_dataset/exp2/lime/hide_rest/beta_\" + jpg_name, img_boundry1)\n",
    "        seg_path = \"annotations/annotations/trimaps/\" + jpg_name[:-3] + \"png\"\n",
    "        tmp_exp2_res = cal_val_from_lime_img(img_boundry1, seg_path=seg_path)\n",
    "        tmp_exp2_res.append(td)\n",
    "        tmp_exp2_res.append(jpg_name)\n",
    "        lime_exp2_res.append(tmp_exp2_res)\n",
    "        print(jpg_name)\n",
    "    except Exception as e:\n",
    "        slack.notify(text=\"えらー\")\n",
    "        print(e)\n",
    "slack.notify(text=\"しゅーりょー\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#txtに書き込み\n",
    "path = \"reslut_pet_dataset/exp2/LIME/result.txt\"\n",
    "with open(path, mode=\"w\") as f:\n",
    "    f.write(\"### num_sumples=1000\")\n",
    "    f.write(\"### 0:領域内でマッピングされてる 1:領域内でマッピングされていない 2:境界線でマッピングされてる 3:境界線でマッピングされていない 4: 領域外でマッピングされている 5:領域外でマッピングされていない 所要時間(sec) ファイル名\")\n",
    "    for i in lime_exp2_res:\n",
    "        f.write(\" \".join(map(str, i)))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 'rate', 'k', '領域内でマッピングされてる', '領域内でマッピングされていない', '境界線でマッピングされてる', '境界線でマッピングされていない', '領域外でマッピングされている', '領域外でマッピングされていない', '所要時間', None), (1, 0.5, 5, 316869, 297481, 83089, 90854, 175235, 290872, 616.1488254070282, None), (2, 0.5, 7, 274313, 340037, 72790, 101153, 157622, 308485, 482.7022244930267, None), (3, 0.5, 9, 240817, 373533, 67503, 106440, 137670, 328437, 407.0907049179077, None), (4, 0.5, 10, 230665, 383685, 61832, 112111, 131753, 334354, 367.2919993400574, None), (5, 0.5, 11, 219753, 394597, 59518, 114425, 127568, 338539, 305.2720651626587, None), (6, 0.5, 13, 202816, 411534, 56197, 117746, 116531, 349576, 264.0714964866638, None), (7, 0.5, 15, 186593, 427757, 50492, 123451, 111590, 354517, 236.6770679950714, None), (8, 0.8, 5, 316869, 297481, 83089, 90854, 175235, 290872, 524.2550642490387, None), (9, 0.8, 7, 274313, 340037, 72790, 101153, 157622, 308485, 397.7610423564911, None), (10, 0.8, 9, 240817, 373533, 67503, 106440, 137670, 328437, 326.3666093349457, None), (11, 0.8, 10, 230665, 383685, 61832, 112111, 131753, 334354, 310.6463599205017, None), (12, 0.8, 11, 219753, 394597, 59518, 114425, 127568, 338539, 290.6079189777374, None), (13, 0.8, 13, 202816, 411534, 56197, 117746, 116531, 349576, 257.4875330924988, None), (14, 0.8, 15, 186593, 427757, 50492, 123451, 111590, 354517, 235.9328229427338, None), (15, 1, 5, 165529, 448821, 36168, 137775, 85340, 380767, 522.5143346786499, None), (16, 1, 7, 143996, 470354, 36935, 137008, 64134, 401973, 397.4503574371338, None), (17, 1, 9, 119644, 494706, 30741, 143202, 53516, 412591, 329.2263658046722, None), (18, 1, 10, 120376, 493974, 28876, 145067, 52644, 413463, 303.2603936195374, None), (19, 1, 11, 103975, 510375, 29309, 144634, 53394, 412713, 283.9984483718872, None), (20, 1, 13, 92203, 522147, 29788, 144155, 49544, 416563, 257.2001330852509, None), (21, 1, 15, 83643, 530707, 22357, 151586, 45772, 420335, 235.3238925933838, None), (None, None, None, None, None, None, None, None, None, None, None), (None, None, None, None, None, None, None, None, None, None, None), ('LIME', None, None, None, None, None, None, None, None, None, None), (None, None, None, 22690, 17748, 1551, 1900, 158, 6129, 59.686243295669556, 'basset_hound_23.jpg'), (None, None, None, 22248, 14500, 3048, 2734, 551, 7095, 60.06644892692566, 'boxer_64.jpg'), (None, None, None, 12795, 10511, 2849, 2412, 3469, 18140, 60.19246053695679, 'newfoundland_198.jpg'), (None, None, None, 13440, 3385, 3463, 3349, 4293, 22246, 60.36270022392273, 'Sphynx_72.jpg'), (None, None, None, 28600, 12067, 1959, 2790, 257, 4503, 60.959733963012695, 'keeshond_6.jpg'), (None, None, None, 15872, 10698, 1833, 5834, 2203, 13736, 62.33847141265869, 'chihuahua_38.jpg'), (None, None, None, 14567, 6721, 5783, 2661, 3806, 16638, 61.35600185394287, 'Siamese_210.jpg'), (None, None, None, 12183, 14096, 4880, 4672, 2148, 12197, 64.13520121574402, 'Egyptian_Mau_118.jpg'), (None, None, None, 18578, 16146, 1997, 3936, 150, 9369, 64.12127161026001, 'Persian_105.jpg'), (None, None, None, 17927, 29271, 1081, 1206, 265, 426, 67.05546140670776, 'keeshond_182.jpg'), (None, None, None, 10508, 1760, 5207, 4044, 4378, 24279, 64.49482369422913, 'Sphynx_46.jpg'), (None, None, None, 21533, 17692, 782, 3992, 248, 5929, 64.77061414718628, 'Birman_68.jpg'), (None, None, None, 11275, 4285, 7001, 3229, 11674, 12712, 64.38454008102417, 'chihuahua_9.jpg'), (None, None, None, 12973, 3535, 4223, 12134, 649, 16662, 64.73567914962769, 'Ragdoll_52.jpg'), (None, None, None, 19992, 14806, 2612, 2983, 573, 9210, 64.82805895805359, 'basset_hound_22.jpg'), (None, None, None, 4239, 4092, 1839, 2664, 11242, 26100, 64.49922299385071, 'scottish_terrier_183.jpg'), (None, None, None, 11842, 9492, 4190, 6648, 5734, 12270, 64.84730815887451, 'chihuahua_61.jpg'), (None, None, None, 7130, 2698, 3190, 4441, 7651, 25066, 64.1076192855835, 'Egyptian_Mau_52.jpg'), (None, None, None, 6530, 5882, 3518, 3308, 3950, 26988, 64.81068158149719, 'Sphynx_230.jpg'), (None, None, None, 12768, 12606, 2187, 4107, 4371, 14137, 64.53031468391418, 'Ragdoll_53.jpg'), (None, None, None, 17239, 11510, 2646, 3895, 4246, 10640, 64.5110867023468, 'newfoundland_186.jpg'), (None, None, None, 17944, 10020, 4370, 4935, 2618, 10289, 64.38274884223938, 'Bombay_21.jpg'), (None, None, None, 1862, 0, 3671, 19, 22399, 22225, 64.17763829231262, 'shiba_inu_93.jpg'), (None, None, None, 17087, 21227, 1354, 5245, 258, 5005, 65.04097294807434, 'Egyptian_Mau_80.jpg'), (None, None, None, 7358, 422, 3620, 1951, 10233, 26592, 64.5801272392273, 'Bengal_113.jpg')]\n"
     ]
    }
   ],
   "source": [
    "#エクセルに書き込み\n",
    "import openpyxl\n",
    "def write_list_2d(sheet, l_2d, start_row, start_col):\n",
    "    for y, row in enumerate(l_2d):\n",
    "        for x, cell in enumerate(row):\n",
    "            sheet.cell(row=start_row + y,\n",
    "                       column=start_col + x,\n",
    "                       value=l_2d[y][x])\n",
    "path = \"reslut_pet_dataset/exp2/dbscan_and_kmeans/300/集計.xlsx\"\n",
    "wb = openpyxl.load_workbook(path)\n",
    "sheet = wb[\"Sheet1\"]\n",
    "l_2d = [ i for i in lime_exp2_res]\n",
    "write_list_2d(sheet=sheet, l_2d=l_2d, start_col=4, start_row=26)\n",
    "print(list(sheet.values)) \n",
    "wb.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_2d = [ i[:-1] for i in lime_exp2_res]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
