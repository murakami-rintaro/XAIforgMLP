{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要な機能\n",
    "\n",
    "元画像の読み込みと処理\n",
    "マッピングされた画像の読み込み\n",
    "バウンティボックスの情報の読み込み\n",
    "処理後のバウンティボックスの座標の算出\n",
    "指標の算出（2つ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Experience_bounding_box():\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        初期化\n",
    "        \"\"\"\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(256),  # (256, 256) で切り抜く。\n",
    "                transforms.CenterCrop(224),  # 画像の中心に合わせて、(224, 224) で切り抜く\n",
    "            ]\n",
    "        )\n",
    "\n",
    " \n",
    "    def open_and_resize_original_image(self, img_path : str) -> Image.Image:\n",
    "        \"\"\"\n",
    "        img_pathの元画像を読み込んでサイズを(244, 244)にして返す\n",
    "        \"\"\"\n",
    "        original_image = Image.open(img_path)\n",
    "        original_image = self.transform(original_image)\n",
    "        \n",
    "        return original_image\n",
    "    \n",
    "    \n",
    "    def open_result_image(self, img_path : str) -> Image.Image:\n",
    "        \"\"\"\n",
    "        img_pathのマッピングされた画像を読み込んで返す（サイズの変更はしない）\n",
    "        \"\"\"\n",
    "        result_image = Image.open(img_path)\n",
    "        \n",
    "        return result_image\n",
    "    \n",
    "    \n",
    "    def get_image_size_and_bounding_box_cornerpoints(self, file_path : str) -> list[tuple]:\n",
    "        \"\"\"\n",
    "        file_pathのxmlファイルから画像サイズとバウンディングボックスの座標を読み込んで返す\n",
    "        [(height, width), (ymin, ymax, xmax, xmin)]\n",
    "        \"\"\"\n",
    "        xml_file = open(file_path)\n",
    "        xmll_tree = ET.parse(xml_file)\n",
    "        root = xmll_tree.getroot()\n",
    "        for obj in root.iter(\"size\"):\n",
    "            h = int(obj.find(\"height\").text)\n",
    "            w = int(obj.find(\"width\").text)\n",
    "        \n",
    "        for obj in root.iter('object'):\n",
    "            xmlbox = obj.find(\"bndbox\")\n",
    "            ymin = int(xmlbox.find('ymin').text)\n",
    "            ymax = int(xmlbox.find('ymax').text)\n",
    "            xmin = int(xmlbox.find('xmin').text)\n",
    "            xmax = int(xmlbox.find('xmax').text)\n",
    "        \n",
    "        \n",
    "        return [(h, w), (ymin, ymax, xmin, xmax)]\n",
    "            \n",
    "    \n",
    "       \n",
    "    def get_resized_box_corner(self, original_size : tuple, original_corner_points : tuple) -> list:\n",
    "        \"\"\"\n",
    "        original_cornerで表されるバウンディングボックスを持つ、サイズがoriginal_size(y, x)の画像が(224, 224)にresizeした後の、\n",
    "        バウンディングボックスのの座標を返す\n",
    "        [ymin, ymax, xmax, xmin]\n",
    "        \"\"\"\n",
    "        h, w = original_size\n",
    "        ymin, ymax, xmin, xmax = original_corner_points\n",
    "        \n",
    "        # xmlファイルの座標は右下原点(?)なので上下左右に反転させて左上原点に直す\n",
    "        # ymin = h - ymin - 1\n",
    "        # ymax = h - ymax - 1\n",
    "        # xmin = w - xmin - 1\n",
    "        # xmax = w - xmax - 1\n",
    "        \n",
    "        # transforms.Resize(256)に相当する座標変換を行う\n",
    "        tmp = min(h, w)\n",
    "        ymin = ymin * 256 // tmp\n",
    "        ymax = ymax * 256 // tmp\n",
    "        xmin = xmin * 256 // tmp\n",
    "        xmax = xmax * 256 // tmp\n",
    "        \n",
    "        # transforms.CenterCrop(224)に相当する座標変換を行う\n",
    "        tmp = (256 - 224) // 2\n",
    "        ymin -= tmp\n",
    "        ymax -= tmp\n",
    "        xmin -= tmp\n",
    "        xmax -= tmp\n",
    "        \n",
    "        return [ymin, ymax, xmin, xmax]\n",
    "    \n",
    "    \n",
    "    def cal_val(self, original_img_path : str, result_img_path : str, xml_path : str) -> list[tuple]:\n",
    "        \"\"\"元画像とマッピングされた画像を読み込んで画素値を比較してマッピングされてるかを判定する方式。上手く働かない（他の箇所も画素値が変わってしまっているため）\"\"\"\n",
    "        # 元画像の読み込みと処理\n",
    "        original_img = self.open_and_resize_original_image(original_img_path)\n",
    "        # マッピングされた画像の読み込み\n",
    "        result_img = self.open_result_image(result_img_path)\n",
    "        # xmlファイルから元画像のサイズと4つの座標の読み込み\n",
    "        original_img_size, bndbox_coordinates = self.get_image_size_and_bounding_box_cornerpoints(xml_path)\n",
    "        # 返還後のバウンディングボックスの4つの頂点の座標の算出\n",
    "        ymin, ymax, xmin, xmax = self.get_resized_box_corner(original_img_size, bndbox_coordinates)\n",
    "        print(ymin, ymax, xmin, xmax)\n",
    "        \n",
    "        count_in_bndbox = [0, 0] # バウンディングボックスの中のマッピングされた割合を記録するためのリスト. 0でマッピングされている, 1でマッピングされていない\n",
    "        count_mapped = [0, 0] # マッピングされた領域のうち、バウンディングボックスの内外にある割合を記録するためのリスト. 0でバウンディングボックスの内側（境界含む）, 1でバウンディングボックスの外側\n",
    "        \n",
    "        mapped_count = 0\n",
    "        bndcount = 0\n",
    "        for i in range(224):\n",
    "            for j in range(224):\n",
    "                #print(original_img.getpixel((i, j)) , result_img.getpixel((i, j)), original_img.getpixel((i, j)) != result_img.getpixel((i, j)))\n",
    "                if ymin <=   i <= ymax and xmin <= j <= xmax:\n",
    "                    bndcount += 1\n",
    "                if original_img.getpixel((i, j)) != result_img.getpixel((i, j)): # マッピングされている\n",
    "                    mapped_count += 1\n",
    "                    if ymin <= i <= ymax and xmin <= j <= xmax: # バウンディングボックスの内側\n",
    "                        count_in_bndbox[0] += 1\n",
    "                        #print(i, j)\n",
    "                        count_mapped[0] += 1\n",
    "                    else:# バウンディングボックスの外側\n",
    "                        count_mapped[1] += 1\n",
    "                elif ymin <= i <= ymax and xmin <= j <= xmax: # マッピングされていないかつバウンディングボックスの内側\n",
    "                    count_in_bndbox[1] += 1\n",
    "        \n",
    "        a, b = count_in_bndbox\n",
    "        count_in_bndbox.append(a * 100 / (a + b))\n",
    "        a, b = count_mapped\n",
    "        count_mapped.append(a * 100 / (a + b))\n",
    "        print(mapped_count)\n",
    "        print(bndcount)\n",
    "        \n",
    "        return[tuple(count_in_bndbox), tuple(count_mapped)]\n",
    "    \n",
    "    #def cal_val_from_mappingdate(self, masks : dict, shap : list, max_rate : float, xml_path : str) -> list[tuple]:\n",
    "    def cal_val_from_mappingdate(self, masks : dict, shap : list, border : float, xml_path : str) -> list[tuple]:\n",
    "        \"\"\"\n",
    "        マッピングした座標のデータ(caのmasks)から算出する\n",
    "        \"\"\"\n",
    "        # xmlファイルから元画像のサイズと4つの座標の読み込み\n",
    "        original_img_size, bndbox_coordinates = self.get_image_size_and_bounding_box_cornerpoints(xml_path)\n",
    "        # 返還後のバウンディングボックスの4つの頂点の座標の算出\n",
    "        ymin, ymax, xmin, xmax = self.get_resized_box_corner(original_img_size, bndbox_coordinates)\n",
    "        \n",
    "        count_in_bndbox = [0, (ymax - ymin + 1) * (xmax - xmin + 1)] # バウンディングボックスの中のマッピングされた割合を記録するためのリスト. 0でマッピングされている, 1でマッピングされていない\n",
    "        count_mapped = [0, 0] # マッピングされた領域のうち、バウンディングボックスの内外にある割合を記録するためのリスト. 0でバウンディングボックスの内側（境界含む）, 1でバウンディングボックスの外側\n",
    "\n",
    "        #border = max(shap) * max_rate\n",
    "        for i in range(len(shap)):\n",
    "            if shap[i] < border:\n",
    "                continue\n",
    "            for y, x in masks[i]: #マッピングされている\n",
    "                if ymin <= y <= ymax and xmin <= x <= xmax: #バウンティボックスの内側\n",
    "                    count_in_bndbox[0] += 1\n",
    "                    count_in_bndbox[1] -= 1\n",
    "                    count_mapped[0] += 1\n",
    "                else:\n",
    "                    count_mapped[1] += 1\n",
    "        a, b = count_in_bndbox\n",
    "        count_in_bndbox.append(a * 100 / (a + b))\n",
    "        a, b = count_mapped\n",
    "        count_mapped.append(a * 100 / (a + b))\n",
    "        \n",
    "        return[tuple(count_in_bndbox), tuple(count_mapped)]\n",
    "    \n",
    "                    \n",
    "                        \n",
    "                        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = Experience_bounding_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = exp1.cal_val_from_mappingdate(masks, shap, 0.8, \"xmls/Abyssinian_13.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reslut1 = exp1.cal_val(\"pet_dataset/Abyssinian_13.jpg\", \"Abyssinian_13_ca_reslut.jpg\", \"xmls/Abyssinian_13.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cluster_ablation as ca\n",
    "import timm\n",
    "\n",
    "import slackweb\n",
    "slack = slackweb.Slack(\"https://hooks.slack.com/services/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\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#モデル作成\n",
    "model = timm.create_model(\"gmlp_s16_224\", pretrained=True)\n",
    "model.eval()\n",
    "print(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"pet_dataset/Abyssinian_13.jpg\"\n",
    "output_path = \"Abyssinian_13_ca_reslut.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "xml_files = glob.glob(\"xmls/*\")\n",
    "file_names = []\n",
    "for file in xml_files:\n",
    "    file_names.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"xmls/Abyssinian_13.xml\"\n",
    "xml_file = open(file_name)\n",
    "xmll_tree = ET.parse(xml_file)\n",
    "root = xmll_tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abyssinian_13.jpg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root[1].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_date = []\n",
    "for file_name in file_names:\n",
    "    xml_file = open(file_name)\n",
    "    xmll_tree = ET.parse(xml_file)\n",
    "    root = xmll_tree.getroot()\n",
    "    for obj in root.iter(\"size\"):\n",
    "        h = int(obj.find(\"height\").text)\n",
    "        w = int(obj.find(\"width\").text)\n",
    "    jpg_name = root[1].text\n",
    "    if min(h, w) < 256 or max(h, w) / min(h, w) >= 1.1:\n",
    "        continue\n",
    "    file_date.append([max(h, w) / min(h, w), jpg_name, file_name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7, 43 猫\n",
    "21, 193 犬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_files_name = [i[1] for i in sorted(file_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abyssinian_169.jpg',\n",
       " 'Abyssinian_178.jpg',\n",
       " 'Bengal_113.jpg',\n",
       " 'Bengal_132.jpg',\n",
       " 'Birman_157.jpg',\n",
       " 'Bombay_166.jpg',\n",
       " 'British_Shorthair_116.jpg',\n",
       " 'Maine_Coon_162.jpg',\n",
       " 'Persian_105.jpg',\n",
       " 'Persian_159.jpg',\n",
       " 'Persian_163.jpg',\n",
       " 'Persian_171.jpg',\n",
       " 'Siamese_17.jpg',\n",
       " 'Sphynx_119.jpg',\n",
       " 'Sphynx_158.jpg',\n",
       " 'Sphynx_164.jpg',\n",
       " 'Sphynx_17.jpg',\n",
       " 'american_bulldog_188.jpg',\n",
       " 'american_pit_bull_terrier_181.jpg',\n",
       " 'american_pit_bull_terrier_187.jpg',\n",
       " 'basset_hound_151.jpg',\n",
       " 'beagle_143.jpg',\n",
       " 'chihuahua_11.jpg',\n",
       " 'english_cocker_spaniel_177.jpg',\n",
       " 'english_cocker_spaniel_186.jpg',\n",
       " 'german_shorthaired_119.jpg',\n",
       " 'havanese_122.jpg',\n",
       " 'japanese_chin_106.jpg',\n",
       " 'keeshond_182.jpg',\n",
       " 'newfoundland_129.jpg',\n",
       " 'newfoundland_180.jpg',\n",
       " 'newfoundland_186.jpg',\n",
       " 'newfoundland_190.jpg',\n",
       " 'pug_15.jpg',\n",
       " 'saint_bernard_178.jpg',\n",
       " 'scottish_terrier_12.jpg',\n",
       " 'scottish_terrier_183.jpg',\n",
       " 'yorkshire_terrier_106.jpg',\n",
       " 'german_shorthaired_164.jpg',\n",
       " 'scottish_terrier_174.jpg',\n",
       " 'american_pit_bull_terrier_121.jpg',\n",
       " 'Sphynx_197.jpg',\n",
       " 'Egyptian_Mau_123.jpg',\n",
       " 'Maine_Coon_133.jpg',\n",
       " 'Abyssinian_167.jpg',\n",
       " 'Abyssinian_119.jpg',\n",
       " 'Abyssinian_190.jpg',\n",
       " 'Bengal_138.jpg',\n",
       " 'Bombay_164.jpg',\n",
       " 'Bombay_189.jpg',\n",
       " 'pomeranian_147.jpg',\n",
       " 'beagle_179.jpg',\n",
       " 'Bengal_160.jpg',\n",
       " 'Maine_Coon_217.jpg',\n",
       " 'pomeranian_190.jpg',\n",
       " 'pug_122.jpg',\n",
       " 'pomeranian_136.jpg',\n",
       " 'Maine_Coon_191.jpg',\n",
       " 'japanese_chin_15.jpg',\n",
       " 'Ragdoll_148.jpg',\n",
       " 'chihuahua_14.jpg',\n",
       " 'miniature_pinscher_101.jpg',\n",
       " 'wheaten_terrier_122.jpg',\n",
       " 'Abyssinian_112.jpg',\n",
       " 'american_pit_bull_terrier_151.jpg',\n",
       " 'japanese_chin_110.jpg',\n",
       " 'pomeranian_122.jpg',\n",
       " 'pomeranian_175.jpg',\n",
       " 'great_pyrenees_134.jpg',\n",
       " 'keeshond_137.jpg',\n",
       " 'leonberger_116.jpg',\n",
       " 'newfoundland_112.jpg',\n",
       " 'scottish_terrier_122.jpg',\n",
       " 'Bombay_172.jpg',\n",
       " 'Bombay_131.jpg',\n",
       " 'american_pit_bull_terrier_120.jpg',\n",
       " 'Bombay_167.jpg',\n",
       " 'havanese_185.jpg',\n",
       " 'Abyssinian_131.jpg',\n",
       " 'american_pit_bull_terrier_140.jpg',\n",
       " 'american_pit_bull_terrier_159.jpg',\n",
       " 'american_pit_bull_terrier_170.jpg',\n",
       " 'english_cocker_spaniel_157.jpg',\n",
       " 'japanese_chin_183.jpg',\n",
       " 'pomeranian_133.jpg',\n",
       " 'Persian_195.jpg',\n",
       " 'Ragdoll_121.jpg',\n",
       " 'Russian_Blue_175.jpg',\n",
       " 'english_cocker_spaniel_105.jpg',\n",
       " 'scottish_terrier_118.jpg',\n",
       " 'american_pit_bull_terrier_143.jpg',\n",
       " 'chihuahua_125.jpg',\n",
       " 'chihuahua_140.jpg',\n",
       " 'Ragdoll_104.jpg',\n",
       " 'keeshond_184.jpg',\n",
       " 'yorkshire_terrier_112.jpg',\n",
       " 'Persian_158.jpg',\n",
       " 'great_pyrenees_130.jpg',\n",
       " 'chihuahua_118.jpg',\n",
       " 'chihuahua_158.jpg',\n",
       " 'pomeranian_121.jpg',\n",
       " 'Ragdoll_112.jpg',\n",
       " 'Sphynx_105.jpg',\n",
       " 'leonberger_167.jpg',\n",
       " 'Sphynx_152.jpg',\n",
       " 'american_pit_bull_terrier_168.jpg',\n",
       " 'chihuahua_111.jpg',\n",
       " 'chihuahua_13.jpg',\n",
       " 'chihuahua_181.jpg',\n",
       " 'chihuahua_183.jpg',\n",
       " 'havanese_182.jpg',\n",
       " 'yorkshire_terrier_15.jpg',\n",
       " 'keeshond_185.jpg',\n",
       " 'Bombay_158.jpg',\n",
       " 'Ragdoll_137.jpg',\n",
       " 'english_setter_177.jpg',\n",
       " 'great_pyrenees_159.jpg',\n",
       " 'newfoundland_183.jpg',\n",
       " 'samoyed_17.jpg',\n",
       " 'Egyptian_Mau_12.jpg',\n",
       " 'chihuahua_150.jpg',\n",
       " 'chihuahua_159.jpg',\n",
       " 'pomeranian_187.jpg',\n",
       " 'pug_173.jpg',\n",
       " 'german_shorthaired_171.jpg',\n",
       " 'havanese_188.jpg',\n",
       " 'yorkshire_terrier_108.jpg',\n",
       " 'Egyptian_Mau_153.jpg',\n",
       " 'scottish_terrier_143.jpg',\n",
       " 'chihuahua_149.jpg',\n",
       " 'Egyptian_Mau_134.jpg',\n",
       " 'german_shorthaired_104.jpg',\n",
       " 'havanese_139.jpg',\n",
       " 'leonberger_182.jpg',\n",
       " 'samoyed_125.jpg',\n",
       " 'american_pit_bull_terrier_14.jpg',\n",
       " 'great_pyrenees_108.jpg',\n",
       " 'Egyptian_Mau_105.jpg',\n",
       " 'leonberger_188.jpg',\n",
       " 'staffordshire_bull_terrier_131.jpg',\n",
       " 'Bombay_100.jpg',\n",
       " 'Bombay_11.jpg',\n",
       " 'Bombay_192.jpg',\n",
       " 'chihuahua_176.jpg',\n",
       " 'Maine_Coon_144.jpg',\n",
       " 'keeshond_107.jpg',\n",
       " 'Sphynx_19.jpg',\n",
       " 'chihuahua_139.jpg',\n",
       " 'staffordshire_bull_terrier_133.jpg',\n",
       " 'yorkshire_terrier_109.jpg',\n",
       " 'Bombay_194.jpg',\n",
       " 'english_setter_123.jpg',\n",
       " 'great_pyrenees_189.jpg',\n",
       " 'miniature_pinscher_111.jpg',\n",
       " 'english_setter_152.jpg',\n",
       " 'staffordshire_bull_terrier_15.jpg',\n",
       " 'chihuahua_173.jpg',\n",
       " 'pug_161.jpg',\n",
       " 'japanese_chin_151.jpg',\n",
       " 'american_pit_bull_terrier_160.jpg',\n",
       " 'chihuahua_147.jpg',\n",
       " 'chihuahua_171.jpg',\n",
       " 'Bengal_105.jpg',\n",
       " 'staffordshire_bull_terrier_109.jpg',\n",
       " 'Egyptian_Mau_151.jpg',\n",
       " 'Abyssinian_102.jpg',\n",
       " 'British_Shorthair_135.jpg',\n",
       " 'american_bulldog_125.jpg',\n",
       " 'chihuahua_115.jpg',\n",
       " 'pug_183.jpg',\n",
       " 'Ragdoll_138.jpg',\n",
       " 'keeshond_149.jpg',\n",
       " 'wheaten_terrier_124.jpg',\n",
       " 'Bombay_140.jpg',\n",
       " 'Abyssinian_172.jpg',\n",
       " 'Abyssinian_122.jpg',\n",
       " 'Bengal_104.jpg',\n",
       " 'Persian_179.jpg',\n",
       " 'Egyptian_Mau_115.jpg',\n",
       " 'leonberger_108.jpg',\n",
       " 'newfoundland_121.jpg',\n",
       " 'saint_bernard_171.jpg',\n",
       " 'Persian_112.jpg',\n",
       " 'Bengal_165.jpg',\n",
       " 'miniature_pinscher_185.jpg',\n",
       " 'Abyssinian_141.jpg',\n",
       " 'Abyssinian_143.jpg',\n",
       " 'american_bulldog_194.jpg',\n",
       " 'havanese_174.jpg',\n",
       " 'Egyptian_Mau_129.jpg',\n",
       " 'Sphynx_179.jpg',\n",
       " 'american_pit_bull_terrier_185.jpg',\n",
       " 'leonberger_104.jpg',\n",
       " 'shiba_inu_183.jpg',\n",
       " 'havanese_100.jpg',\n",
       " 'leonberger_179.jpg',\n",
       " 'wheaten_terrier_123.jpg',\n",
       " 'pug_163.jpg',\n",
       " 'staffordshire_bull_terrier_186.jpg',\n",
       " 'British_Shorthair_113.jpg',\n",
       " 'havanese_135.jpg',\n",
       " 'american_pit_bull_terrier_102.jpg',\n",
       " 'chihuahua_174.jpg',\n",
       " 'pomeranian_160.jpg',\n",
       " 'pomeranian_167.jpg',\n",
       " 'pug_190.jpg',\n",
       " 'Persian_118.jpg',\n",
       " 'beagle_119.jpg',\n",
       " 'shiba_inu_186.jpg',\n",
       " 'Bengal_101.jpg',\n",
       " 'chihuahua_129.jpg',\n",
       " 'havanese_178.jpg',\n",
       " 'samoyed_139.jpg']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_files_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [\"pet_dataset/Maine_Coon_162.jpg\", \"pet_dataset/Maine_Coon_133.jpg\", \"pet_dataset/beagle_143.jpg\", \"pet_dataset/shiba_inu_183.jpg\"]\n",
    "xml_files = ['xmls/Maine_Coon_162.xml', 'xmls/Maine_Coon_133.xml', 'xmls/beagle_143.xml', 'xmls/shiba_inu_183.xml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_oc = []\n",
    "exp = ca.cluster_ablation(model)\n",
    "for inputs in test_files:\n",
    "    p, pred = exp.only_clustering(inputs, mode=\"DK\", border=300, eps=15, min_samples=5, k=10)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in p:\n",
    "        y.append(i[0])\n",
    "        x.append(i[1])\n",
    "    res_oc.append([len(p), p, pred, y, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = res_oc[0][-2:]\n",
    "pred = res_oc[0][2]\n",
    "plt.scatter(x, y, s=100,c = pred,cmap=\"Blues\")\n",
    "plt.xlim(0, 223)\n",
    "plt.ylim(223, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import Delaunay\n",
    "def in_hull_(point : list, hull : list):\n",
    "    \"\"\"点群hullからなる凸包内に点pointが入っているかを判定\"\"\"\n",
    "    if not isinstance(hull, Delaunay):\n",
    "        hull = Delaunay(hull)\n",
    "    return hull.find_simplex(point) >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = {}\n",
    "for c in list(set(pred)):\n",
    "    cluster[c] = []\n",
    "for v, u, c in zip(y, x, pred):\n",
    "    cluster[c].append([v, u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tmp = torch.zeros((3, 224, 224))\n",
    "for i in range(224):\n",
    "    for j in range(224):\n",
    "        if tmp[0, 0, 0] != 0:\n",
    "            continue\n",
    "        for c in range(10):\n",
    "            if in_hull_([i, j], cluster[c]):\n",
    "                for k in range(3):\n",
    "                    tmp[k, i, j] = 25 * (c + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tmp.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = []\n",
    "for inputs in test_files:\n",
    "    p, pred = exp.only_clustering(inputs, mode=\"DK\", border=300, eps=15, min_samples=5, k=10)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in p:\n",
    "        y.append(i[0])\n",
    "        x.append(i[1])\n",
    "    res2.append([len(p), p, pred, y, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ca.cluster_ablation(model)\n",
    "res = []\n",
    "count = 0\n",
    "for img in test_files[:1]:\n",
    "    #masked_img, masks, mask_flag = exp.calc_prob_save_img_by_dbscan_and_kmeans(input_path=img, output_path=\"tmp_reslut.jpg\", border=300, eps=15, min_samples=5, k=10)\n",
    "    #res.append([masked_img, masks, mask_flag])\n",
    "    #probs, value, value_beta, masked_img, masks = exp.calc_prob_save_img_by_dbscan_and_kmeans(input_path=img, output_path=\"tmp_reslut.jpg\", border=300, eps=15, min_samples=5, k=10)\n",
    "    #res.append([value, value_beta, probs, masked_img, masks])\n",
    "    count += 1\n",
    "    #print(count)\n",
    "    #continue\n",
    "    values, p, pred, masks, base_img, masked_img = exp.calc_prob_save_img_by_dbscan_and_kmeans(input_path=img, output_path=\"tmp_reslut.jpg\", border=300, eps=15, min_samples=5, k=10)\n",
    "    res.append([values, p, pred, masks, base_img, masked_img])\n",
    "    print(count)\n",
    "slack.notify(text=\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_img = [i[-1] for i in res]\n",
    "tmp_img = [i[-2] for i in res]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tmp_img[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(masked_img[0][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in values_beta:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tmp_img = torch.zeros((3, 224, 224))\n",
    "for i in range(224):\n",
    "    for j in range(224):\n",
    "        for c in range(10):\n",
    "            if in_hull_([i, j], masks[c]):\n",
    "                for l in range(3):\n",
    "                    tmp_img[l, i, j] = 25 * (c + 1)\n",
    "plt.imshow(tmp_img.permute(1,2,0))\n",
    "slack.notify(text=\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masked_img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xx, yy, s=100,c = col,cmap=\"Blues\")\n",
    "plt.xlim(0, 223)\n",
    "plt.ylim(223, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in res[:1]:\n",
    "    plt.imshow(i[3][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n",
    "y, x = res2[i][-2:]\n",
    "pred = res2[i][2]\n",
    "plt.scatter(x, y, s=100,c = pred,cmap=\"Blues\")\n",
    "plt.xlim(0, 223)\n",
    "plt.ylim(223, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap, p, pred, masks = exp.calc_shapley_save_img(\"cat.jpg\", \"cat_reslut_450_9_10.jpg\", mode=\"D\",border=450,eps=9, min_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ca.cluster_ablation(model)\n",
    "exp1 = Experience_bounding_box()\n",
    "error = []\n",
    "res1 = []\n",
    "count = 0\n",
    "for img_path, xml_path in zip(test_files, xml_files):\n",
    "    try:\n",
    "        shap, p, pred, masks  = exp.calc_shapley_save_img_by_dbscan_and_kmeans(img_path, \"reslut_pet_dataset/exp1/dbscan_and_kmeans/300/take2/\" + img_path[12:-4] + \".jpg\", border=300,eps=15, min_samples=5,k=10,max_rate=0.8)\n",
    "        #n_c  = exp.calc_shapley_save_img(img_path, \"reslut_pet_dataset/exp1/k_means/300/\" + img_path[12:-4] + \"_{}_{}.jpg\".format(n_c, rate), border=300,eps=eps, min_samples = min_samples)\n",
    "        res = exp1.cal_val_from_mappingdate(masks=masks, shap=shap, max_rate=0.8, xml_path=xml_path)\n",
    "        tmp = [img_path, res]\n",
    "        res1.append(tmp)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        error.append([img_path])\n",
    "        pass\n",
    "    count += 1\n",
    "    print(count)\n",
    "slack.notify(text=\"実行終了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ca.cluster_ablation(model)\n",
    "exp1 = Experience_bounding_box()\n",
    "error = []\n",
    "reslut_n_c = []\n",
    "reslut3 = []\n",
    "count = 0\n",
    "for rate in [5]:\n",
    "    for n_c in range(4, 11, 2):\n",
    "        for img_path, xml_path in zip(test_files, xml_files):\n",
    "            try:\n",
    "                shap, p, pred, masks  = exp.calc_shapley_save_img_by_kmeans(img_path, \"reslut_pet_dataset/exp1/k_means/300/\" + img_path[12:-4] + \"{}.jpg\".format(n_c), border=300,num_cluster=n_c, max_rate=rate * 0.1)\n",
    "                #n_c  = exp.calc_shapley_save_img(img_path, \"reslut_pet_dataset/exp1/k_means/300/\" + img_path[12:-4] + \"_{}_{}.jpg\".format(n_c, rate), border=300,eps=eps, min_samples = min_samples)\n",
    "                res = exp1.cal_val_from_mappingdate(masks=masks, shap=shap, max_rate=rate * 0.1, xml_path=xml_path)\n",
    "                tmp = [img_path, n_c, res]\n",
    "                reslut_n_c.append([img_path, n_c])\n",
    "                reslut3.append(tmp)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                error.append([img_path, n_c])\n",
    "                pass\n",
    "        count += 1\n",
    "        print(count)\n",
    "slack.notify(text=\"実行終了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ca.cluster_ablation(model)\n",
    "exp1 = Experience_bounding_box()\n",
    "error = []\n",
    "reslut_n_c = []\n",
    "result_k_600 = []\n",
    "count = 0\n",
    "for rate in [5]:\n",
    "    for n_c in range(4, 11, 2):\n",
    "        for img_path, xml_path in zip(test_files, xml_files):\n",
    "            try:\n",
    "                shap, p, pred, masks  = exp.calc_shapley_save_img_by_kmeans(img_path, \"reslut_pet_dataset/exp1/k_means/600/\" + img_path[12:-4] + \"{}.jpg\".format(n_c), border=600,num_cluster=n_c, max_rate=rate * 0.1)\n",
    "                #n_c  = exp.calc_shapley_save_img(img_path, \"reslut_pet_dataset/exp1/k_means/300/\" + img_path[12:-4] + \"_{}_{}.jpg\".format(n_c, rate), border=300,eps=eps, min_samples = min_samples)\n",
    "                res = exp1.cal_val_from_mappingdate(masks=masks, shap=shap, max_rate=rate * 0.1, xml_path=xml_path)\n",
    "                tmp = [img_path, n_c, res]\n",
    "                #reslut_n_c.append([img_path, n_c])\n",
    "                result_k_450.append(tmp)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                error.append([img_path, n_c])\n",
    "                pass\n",
    "        count += 1\n",
    "        print(count)\n",
    "slack.notify(text=\"実行終了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_k_450[:len(result_k_450) // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ca.cluster_ablation(model)\n",
    "exp1 = Experience_bounding_box()\n",
    "error = []\n",
    "reslut_n_c = []\n",
    "reslut3 = []\n",
    "\n",
    "for rate in [5, 6, 7]:\n",
    "    for eps in range(5, 10):# 5 16 2\n",
    "        for min_samples in range(5, 10):# 10 31 2\n",
    "                for img_path, xml_path in zip(test_files, xml_files):\n",
    "                    try:\n",
    "                        shap, p, pred, masks  = exp.calc_shapley_save_img(img_path, \"reslut_pet_dataset/exp1/300/\" + img_path[12:-4] + \"{}_{}.jpg\".format(eps, min_samples), mode=\"D\", border=300,eps=eps, min_samples = min_samples)\n",
    "                        n_c  = exp.calc_shapley_save_img(img_path, \"reslut_pet_dataset/exp1/300/\" + img_path[12:-4] + \"_{}_{}_{}.jpg\".format(eps, min_samples, rate), mode=\"D\", border=300,eps=eps, min_samples = min_samples)\n",
    "                        res = exp1.cal_val_from_mappingdate(masks=masks, shap=shap, max_rate=rate * 0.1, xml_path=xml_path)\n",
    "                        tmp = [img_path, eps, min_samples, res]\n",
    "                        reslut_n_c.append([eps, min_samples, img_path, n_c])\n",
    "                        reslut3.append(tmp)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        error.append([img_path, eps, min_samples])\n",
    "                        pass\n",
    "slack.notify(text=\"実行終了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ca.cluster_ablation(model)\n",
    "exp1 = Experience_bounding_box()\n",
    "error = []\n",
    "result_exp1 = []\n",
    "for eps, min_samples in eps_min_sample:\n",
    "    for img_path, xml_path in zip(test_files, xml_files):\n",
    "        try:\n",
    "            shap, p, pred, masks  = exp.calc_shapley_save_img(img_path, \"reslut_pet_dataset/exp1/300/\" + img_path[12:-4] + \"{}_{}.jpg\".format(eps, min_samples), mode=\"D\", border=300,eps=eps, min_samples = min_samples)\n",
    "            #n_c  = exp.calc_shapley_save_img(img_path, \"reslut_pet_dataset/exp1/300/\" + img_path[12:-4] + \"{}_{}.jpg\".format(eps, min_samples), mode=\"D\", border=300,eps=eps, min_samples = min_samples)\n",
    "            res = exp1.cal_val_from_mappingdate(masks=masks, shap=shap, max_rate=0.8, xml_path=xml_path)\n",
    "            tmp = [img_path, eps, min_samples, res]\n",
    "            result_exp1.append(tmp)\n",
    "            #reslut_n_c.append([eps, min_samples, img_path, n_c])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error.append([img_path, eps, min_samples, e])\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_means\n",
    "exp = ca.cluster_ablation(model)\n",
    "exp1 = Experience_bounding_box()\n",
    "error = []\n",
    "\n",
    "for border in [300, 450, 600]:\n",
    "    for img_path, xml_path in zip(test_files, xml_files):\n",
    "        try:\n",
    "            shap, p, pred, masks  = exp.calc_shapley_save_img(img_path, \"reslut_pet_dataset/exp1/x_means/{}\".format(border) + img_path[:-4] + \".jpg\", mode=\"X\", border=border)\n",
    "            res = exp1.cal_val_from_mappingdate(masks=masks, shap=shap, max_rate=0.8, xml_path=xml_path)\n",
    "            tmp = [img_path, eps, min_samples, res, len(masks)]\n",
    "            reslut1.append(tmp)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error.append([img_path, eps, min_samples])\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [150, 450, 600]:\n",
    "    cat_result = exp.calc_shapley_save_img_by_xmeans(input_path=\"cat.jpg\", output_path = \"cat_reslut_{}_x.jpg\".format(i), border=i,max_rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_result = exp.calc_shapley_save_img_by_kmeans(input_path=\"cat.jpg\", output_path = \"cat_reslut_300_k_7.jpg\", border=300,num_cluster=7,max_rate=0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
